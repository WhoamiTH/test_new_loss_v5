/home/z5102138/anaconda3/envs/py36/bin/python
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_1.csv
./test_glass5/model_MLP_20000_0.24/record_1/MLP_20000_0.24_1
----------------------



epoch 1, loss 0.9939, train acc 4.68%, f1 0.0894, precision 0.0468, recall 1.0000, auc 0.5000
epoch 501, loss 0.1620, train acc 90.06%, f1 0.4848, precision 0.3200, recall 1.0000, auc 0.9479
epoch 1001, loss 0.0369, train acc 98.25%, f1 0.8421, precision 0.7273, recall 1.0000, auc 0.9908
epoch 1501, loss 0.0107, train acc 99.42%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9969
epoch 2001, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 2501, loss 0.0054, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3001, loss 0.0005, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3501, loss 0.0012, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4001, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4501, loss 0.0003, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5501, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6001, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6501, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7501, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8501, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9001, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10501, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13001, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16501, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
running_time is 1714.162236356
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_1.csv
./test_glass5/standlization_data/glass5_std_test_1.csv
MLP_20000_0.24
normal_0.5
./test_glass5/model_MLP_20000_0.24/record_1/MLP_20000_0.24_1
./test_glass5/result_MLP_20000_0.24_normal_0.5/record_1/
----------------------



the AUC is 0.8095238095238095

the Fscore is 0.1111111111111111

the precision is 0.058823529411764705

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_2.csv
./test_glass5/model_MLP_20000_0.24/record_1/MLP_20000_0.24_2
----------------------



epoch 1, loss 0.9944, train acc 4.68%, f1 0.0791, precision 0.0412, recall 1.0000, auc 0.5030
epoch 501, loss 0.0909, train acc 94.74%, f1 0.6087, precision 0.4375, recall 1.0000, auc 0.9726
epoch 1001, loss 0.0866, train acc 98.25%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.9909
epoch 1501, loss 0.0098, train acc 98.83%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9939
epoch 2001, loss 0.0320, train acc 98.83%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9939
epoch 2501, loss 0.0044, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3001, loss 0.0009, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3501, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4001, loss 0.0005, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5001, loss 0.0293, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6001, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7501, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8001, loss 0.0311, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8501, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9001, loss 0.0317, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10001, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10501, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14001, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14501, loss 0.0297, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15501, loss 0.0297, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16001, loss 0.0297, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17001, loss 0.0297, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17501, loss 0.0297, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18501, loss 0.0291, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
running_time is 1742.373462132
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_2.csv
./test_glass5/standlization_data/glass5_std_test_2.csv
MLP_20000_0.24
normal_0.5
./test_glass5/model_MLP_20000_0.24/record_1/MLP_20000_0.24_2
./test_glass5/result_MLP_20000_0.24_normal_0.5/record_1/
----------------------



the AUC is 0.951219512195122

the Fscore is 0.5

the precision is 0.3333333333333333

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_3.csv
./test_glass5/model_MLP_20000_0.24/record_1/MLP_20000_0.24_3
----------------------



epoch 1, loss 0.9943, train acc 5.85%, f1 0.0800, precision 0.0417, recall 1.0000, auc 0.5091
epoch 501, loss 0.0297, train acc 95.32%, f1 0.6364, precision 0.4667, recall 1.0000, auc 0.9756
epoch 1001, loss 0.0287, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 1501, loss 0.0082, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 2001, loss 0.0055, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 2501, loss 0.0003, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3001, loss 0.0010, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3501, loss 0.0010, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4001, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4501, loss 0.0003, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6001, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7501, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10501, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19501, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
running_time is 1745.622262526
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_3.csv
./test_glass5/standlization_data/glass5_std_test_3.csv
MLP_20000_0.24
normal_0.5
./test_glass5/model_MLP_20000_0.24/record_1/MLP_20000_0.24_3
./test_glass5/result_MLP_20000_0.24_normal_0.5/record_1/
----------------------



the AUC is 0.8780487804878049

the Fscore is 0.2857142857142857

the precision is 0.16666666666666666

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_4.csv
./test_glass5/model_MLP_20000_0.24/record_1/MLP_20000_0.24_4
----------------------



epoch 1, loss 0.9944, train acc 14.62%, f1 0.0875, precision 0.0458, recall 1.0000, auc 0.5549
epoch 501, loss 0.1348, train acc 95.32%, f1 0.6364, precision 0.4667, recall 1.0000, auc 0.9756
epoch 1001, loss 0.0396, train acc 98.83%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9939
epoch 1501, loss 0.0007, train acc 98.83%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9939
epoch 2001, loss 0.0096, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 2501, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3001, loss 0.0010, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3501, loss 0.0010, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4001, loss 0.0009, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4501, loss 0.0005, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5001, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5501, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6501, loss 0.0291, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7001, loss 0.0291, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7501, loss 0.0291, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8001, loss 0.0298, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11001, loss 0.0304, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12501, loss 0.0304, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14001, loss 0.0310, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16501, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17001, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19501, loss 0.0291, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
running_time is 1745.629861095
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_4.csv
./test_glass5/standlization_data/glass5_std_test_4.csv
MLP_20000_0.24
normal_0.5
./test_glass5/model_MLP_20000_0.24/record_1/MLP_20000_0.24_4
./test_glass5/result_MLP_20000_0.24_normal_0.5/record_1/
----------------------



the AUC is 0.9146341463414633

the Fscore is 0.3636363636363636

the precision is 0.2222222222222222

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_5.csv
./test_glass5/model_MLP_20000_0.24/record_1/MLP_20000_0.24_5
----------------------



epoch 1, loss 0.9943, train acc 4.07%, f1 0.0782, precision 0.0407, recall 1.0000, auc 0.5000
epoch 501, loss 0.0686, train acc 94.19%, f1 0.5833, precision 0.4118, recall 1.0000, auc 0.9697
epoch 1001, loss 0.0505, train acc 97.67%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.9879
epoch 1501, loss 0.0592, train acc 98.26%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.9909
epoch 2001, loss 0.0064, train acc 98.84%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9939
epoch 2501, loss 0.0032, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3001, loss 0.0017, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3501, loss 0.0323, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4001, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4501, loss 0.0306, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5001, loss 0.0302, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5501, loss 0.0002, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6001, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6501, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8001, loss 0.0291, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8501, loss 0.0298, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11001, loss 0.0304, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11501, loss 0.0297, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12501, loss 0.0297, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14001, loss 0.0291, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15501, loss 0.0297, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16501, loss 0.0291, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19501, loss 0.0291, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
running_time is 1815.221407795
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_5.csv
./test_glass5/standlization_data/glass5_std_test_5.csv
MLP_20000_0.24
normal_0.5
./test_glass5/model_MLP_20000_0.24/record_1/MLP_20000_0.24_5
./test_glass5/result_MLP_20000_0.24_normal_0.5/record_1/
----------------------



the AUC is 0.975

the Fscore is 0.6666666666666666

the precision is 0.5

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_1.csv
./test_glass5/model_MLP_20000_0.25/record_1/MLP_20000_0.25_1
----------------------



epoch 1, loss 0.9809, train acc 5.85%, f1 0.0904, precision 0.0473, recall 1.0000, auc 0.5061
epoch 501, loss 0.1293, train acc 91.23%, f1 0.5161, precision 0.3478, recall 1.0000, auc 0.9540
epoch 1001, loss 0.0837, train acc 95.91%, f1 0.6957, precision 0.5333, recall 1.0000, auc 0.9785
epoch 1501, loss nan, train acc 99.42%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9969
epoch 2001, loss 0.0049, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 2501, loss 0.0012, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3001, loss 0.0005, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3501, loss 0.0003, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4001, loss 0.0035, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4501, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5001, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5501, loss 0.0011, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6501, loss 0.0003, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7001, loss 0.0005, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8001, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11001, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
running_time is 1608.338004965
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_1.csv
./test_glass5/standlization_data/glass5_std_test_1.csv
MLP_20000_0.25
normal_0.5
./test_glass5/model_MLP_20000_0.25/record_1/MLP_20000_0.25_1
./test_glass5/result_MLP_20000_0.25_normal_0.5/record_1/
----------------------



the AUC is 0.8928571428571428

the Fscore is 0.18181818181818182

the precision is 0.1

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_2.csv
./test_glass5/model_MLP_20000_0.25/record_1/MLP_20000_0.25_2
----------------------



epoch 1, loss 0.9809, train acc 4.09%, f1 0.0787, precision 0.0409, recall 1.0000, auc 0.5000
epoch 501, loss 0.0777, train acc 95.32%, f1 0.6364, precision 0.4667, recall 1.0000, auc 0.9756
epoch 1001, loss 0.0157, train acc 98.25%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.9909
epoch 1501, loss 0.0213, train acc 98.83%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9939
epoch 2001, loss 0.0069, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 2501, loss 0.0021, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3001, loss 0.0010, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3501, loss 0.0290, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4001, loss 0.0005, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4501, loss 0.0005, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5001, loss 0.0002, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5501, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6001, loss 0.0002, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6501, loss 0.0284, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7501, loss 0.0296, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8501, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9001, loss 0.0289, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9501, loss 0.0289, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10501, loss 0.0289, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11501, loss 0.0283, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14501, loss 0.0283, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18001, loss 0.0289, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19001, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19501, loss 0.0283, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
running_time is 1572.250804353
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_2.csv
./test_glass5/standlization_data/glass5_std_test_2.csv
MLP_20000_0.25
normal_0.5
./test_glass5/model_MLP_20000_0.25/record_1/MLP_20000_0.25_2
./test_glass5/result_MLP_20000_0.25_normal_0.5/record_1/
----------------------



the AUC is 0.701219512195122

the Fscore is 0.28571428571428575

the precision is 0.2

the recall is 0.5

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_3.csv
./test_glass5/model_MLP_20000_0.25/record_1/MLP_20000_0.25_3
----------------------



epoch 1, loss 0.9809, train acc 23.39%, f1 0.0709, precision 0.0373, recall 0.7143, auc 0.4639
epoch 501, loss 0.0829, train acc 94.74%, f1 0.6087, precision 0.4375, recall 1.0000, auc 0.9726
epoch 1001, loss 0.0315, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 1501, loss 0.0096, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 2001, loss 0.0012, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 2501, loss 0.0033, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3501, loss 0.0003, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4001, loss 0.0012, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4501, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5001, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5501, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6001, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6501, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7001, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8001, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9001, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9501, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12001, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17501, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
running_time is 1588.454616351
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_3.csv
./test_glass5/standlization_data/glass5_std_test_3.csv
MLP_20000_0.25
normal_0.5
./test_glass5/model_MLP_20000_0.25/record_1/MLP_20000_0.25_3
./test_glass5/result_MLP_20000_0.25_normal_0.5/record_1/
----------------------



the AUC is 0.676829268292683

the Fscore is 0.22222222222222224

the precision is 0.14285714285714285

the recall is 0.5

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_4.csv
./test_glass5/model_MLP_20000_0.25/record_1/MLP_20000_0.25_4
----------------------



epoch 1, loss 0.9808, train acc 6.43%, f1 0.0805, precision 0.0419, recall 1.0000, auc 0.5122
epoch 501, loss 0.0622, train acc 95.91%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.9787
epoch 1001, loss 0.0512, train acc 98.83%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9939
epoch 1501, loss 0.0147, train acc 98.83%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9939
epoch 2001, loss 0.0050, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 2501, loss 0.0017, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3001, loss 0.0016, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3501, loss 0.0008, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4501, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5001, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5501, loss 0.0003, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7001, loss 0.0283, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9001, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10501, loss 0.0283, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13001, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14001, loss 0.0295, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14501, loss 0.0295, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16501, loss 0.0295, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18001, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
running_time is 1613.174217448
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_4.csv
./test_glass5/standlization_data/glass5_std_test_4.csv
MLP_20000_0.25
normal_0.5
./test_glass5/model_MLP_20000_0.25/record_1/MLP_20000_0.25_4
./test_glass5/result_MLP_20000_0.25_normal_0.5/record_1/
----------------------



the AUC is 0.9390243902439024

the Fscore is 0.4444444444444445

the precision is 0.2857142857142857

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_5.csv
./test_glass5/model_MLP_20000_0.25/record_1/MLP_20000_0.25_5
----------------------



epoch 1, loss 0.9806, train acc 50.58%, f1 0.1414, precision 0.0761, recall 1.0000, auc 0.7424
epoch 501, loss 0.1141, train acc 92.44%, f1 0.5185, precision 0.3500, recall 1.0000, auc 0.9606
epoch 1001, loss 0.0180, train acc 98.84%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9939
epoch 1501, loss 0.0115, train acc 98.84%, f1 0.8750, precision 0.7778, recall 1.0000, auc 0.9939
epoch 2001, loss 0.0040, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 2501, loss 0.0012, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3001, loss 0.0291, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3501, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4001, loss 0.0005, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4501, loss 0.0004, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5001, loss 0.0004, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5501, loss 0.0284, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6001, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6501, loss 0.0302, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7001, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7501, loss 0.0289, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10001, loss 0.0295, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10501, loss 0.0295, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11001, loss 0.0289, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14501, loss 0.0289, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16501, loss 0.0289, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18001, loss 0.0283, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19001, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
running_time is 1580.511621059
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_5.csv
./test_glass5/standlization_data/glass5_std_test_5.csv
MLP_20000_0.25
normal_0.5
./test_glass5/model_MLP_20000_0.25/record_1/MLP_20000_0.25_5
./test_glass5/result_MLP_20000_0.25_normal_0.5/record_1/
----------------------



the AUC is 1.0

the Fscore is 1.0

the precision is 1.0

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_1.csv
./test_glass5/model_MLP_20000_0.26/record_1/MLP_20000_0.26_1
----------------------



epoch 1, loss 0.9673, train acc 5.85%, f1 0.0904, precision 0.0473, recall 1.0000, auc 0.5061
epoch 501, loss 0.0961, train acc 94.15%, f1 0.6154, precision 0.4444, recall 1.0000, auc 0.9693
epoch 1001, loss 0.0231, train acc 99.42%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9969
epoch 1501, loss 0.0123, train acc 99.42%, f1 0.9412, precision 0.8889, recall 1.0000, auc 0.9969
epoch 2001, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 2501, loss 0.0008, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3001, loss 0.0006, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3501, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4001, loss 0.0004, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4501, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5001, loss 0.0005, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5501, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6001, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6501, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7001, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8001, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9001, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17001, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
running_time is 1628.1449402
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_1.csv
./test_glass5/standlization_data/glass5_std_test_1.csv
MLP_20000_0.26
normal_0.5
./test_glass5/model_MLP_20000_0.26/record_1/MLP_20000_0.26_1
./test_glass5/result_MLP_20000_0.26_normal_0.5/record_1/
----------------------



the AUC is 0.4880952380952381

the Fscore is 0.0

the precision is 0.0

the recall is 0.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_2.csv
./test_glass5/model_MLP_20000_0.26/record_1/MLP_20000_0.26_2
----------------------



epoch 1, loss 0.9674, train acc 40.35%, f1 0.1053, precision 0.0561, recall 0.8571, auc 0.6206
epoch 501, loss 0.1475, train acc 91.81%, f1 0.5000, precision 0.3333, recall 1.0000, auc 0.9573
epoch 1001, loss 0.0522, train acc 97.66%, f1 0.7778, precision 0.6364, recall 1.0000, auc 0.9878
epoch 1501, loss 0.0219, train acc 98.25%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.9909
epoch 2001, loss 0.0121, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 2501, loss 0.0318, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3001, loss 0.0005, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 3501, loss 0.0005, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4001, loss 0.0283, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 4501, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5001, loss 0.0004, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 5501, loss 0.0002, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6001, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 6501, loss 0.0281, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 7501, loss 0.0287, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 8501, loss 0.0281, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 9501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 10501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 11501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12001, loss 0.0281, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 12501, loss 0.0001, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 13501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 14501, loss 0.0281, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 15501, loss 0.0275, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16001, loss 0.0281, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 16501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 17501, loss nan, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18001, loss 0.0281, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 18501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19001, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
epoch 19501, loss 0.0000, train acc 99.42%, f1 0.9333, precision 0.8750, recall 1.0000, auc 0.9970
running_time is 1618.5685472480002
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_2.csv
./test_glass5/standlization_data/glass5_std_test_2.csv
MLP_20000_0.26
normal_0.5
./test_glass5/model_MLP_20000_0.26/record_1/MLP_20000_0.26_2
./test_glass5/result_MLP_20000_0.26_normal_0.5/record_1/
----------------------



the AUC is 0.9390243902439024

the Fscore is 0.4444444444444445

the precision is 0.2857142857142857

the recall is 1.0

Done
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_3.csv
./test_glass5/model_MLP_20000_0.26/record_1/MLP_20000_0.26_3
----------------------



epoch 1, loss 0.9679, train acc 14.62%, f1 0.0759, precision 0.0397, recall 0.8571, auc 0.4865
epoch 501, loss 0.1177, train acc 95.32%, f1 0.6364, precision 0.4667, recall 1.0000, auc 0.9756
epoch 1001, loss 0.0409, train acc 98.25%, f1 0.8235, precision 0.7000, recall 1.0000, auc 0.9909
epoch 1501, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 2001, loss 0.0120, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 2501, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3001, loss 0.0004, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 3501, loss 0.0024, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4001, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 4501, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5001, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 5501, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6001, loss 0.0002, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 6501, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7001, loss 0.0001, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 7501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 8501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 9501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10001, loss nan, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 10501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 11501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 12501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 13501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 14501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 15501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 16501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 17501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 18501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19001, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
epoch 19501, loss 0.0000, train acc 100.00%, f1 1.0000, precision 1.0000, recall 1.0000, auc 1.0000
running_time is 1648.740827861
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/z5102138/anaconda3/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:104: UserWarning: 
A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
./test_glass5/standlization_data/glass5_std_train_3.csv
./test_glass5/standlization_data/glass5_std_test_3.csv
MLP_20000_0.26
normal_0.5
./test_glass5/model_MLP_20000_0.26/record_1/MLP_20000_0.26_3
./test_glass5/result_MLP_20000_0.26_normal_0.5/record_1/
----------------------



the AUC is 0.676829268292683

the Fscore is 0.22222222222222224

the precision is 0.14285714285714285

the recall is 0.5

Done
=>> PBS: job killed: walltime 43282 exceeded limit 43200
